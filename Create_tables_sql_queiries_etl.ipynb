{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "database \"sparkifydb\" is being accessed by other users\nDETAIL:  There are 3 other sessions using the database.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-6ba5ae63764f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-6ba5ae63764f>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;34m-\u001b[0m \u001b[0mFinally\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcloses\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \"\"\"\n\u001b[0;32m---> 61\u001b[0;31m     \u001b[0mcur\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_database\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0mdrop_tables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-6ba5ae63764f>\u001b[0m in \u001b[0;36mcreate_database\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# create sparkify database with UTF8 encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"DROP DATABASE IF EXISTS sparkifydb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"CREATE DATABASE sparkifydb WITH ENCODING 'utf8' TEMPLATE template0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOperationalError\u001b[0m: database \"sparkifydb\" is being accessed by other users\nDETAIL:  There are 3 other sessions using the database.\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "from sql_queries import create_table_queries, drop_table_queries\n",
    "\n",
    "\n",
    "def create_database():\n",
    "    \"\"\"\n",
    "    - Creates and connects to the sparkifydb\n",
    "    - Returns the connection and cursor to sparkifydb\n",
    "    \"\"\"\n",
    "    \n",
    "    # connect to default database\n",
    "    conn = psycopg2.connect(\"host=127.0.0.1 dbname=studentdb user=student password=student\")\n",
    "    conn.set_session(autocommit=True)\n",
    "    cur = conn.cursor()\n",
    "    \n",
    "    # create sparkify database with UTF8 encoding\n",
    "    cur.execute(\"DROP DATABASE IF EXISTS sparkifydb\")\n",
    "    cur.execute(\"CREATE DATABASE sparkifydb WITH ENCODING 'utf8' TEMPLATE template0\")\n",
    "\n",
    "    # close connection to default database\n",
    "    conn.close()    \n",
    "    \n",
    "    # connect to sparkify database\n",
    "    conn = psycopg2.connect(\"host=127.0.0.1 dbname=sparkifydb user=student password=student\")\n",
    "    cur = conn.cursor()\n",
    "    \n",
    "    return cur, conn\n",
    "\n",
    "\n",
    "def drop_tables(cur, conn):\n",
    "    \"\"\"\n",
    "    Drops each table using the queries in `drop_table_queries` list.\n",
    "    \"\"\"\n",
    "    for query in drop_table_queries:\n",
    "        cur.execute(query)\n",
    "        conn.commit()\n",
    "\n",
    "\n",
    "def create_tables(cur, conn):\n",
    "    \"\"\"\n",
    "    Creates each table using the queries in `create_table_queries` list. \n",
    "    \"\"\"\n",
    "    for query in create_table_queries:\n",
    "        cur.execute(query)\n",
    "        conn.commit()\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    - Drops (if exists) and Creates the sparkify database. \n",
    "    \n",
    "    - Establishes connection with the sparkify database and gets\n",
    "    cursor to it.  \n",
    "    \n",
    "    - Drops all the tables.  \n",
    "    \n",
    "    - Creates all tables needed. \n",
    "    \n",
    "    - Finally, closes the connection. \n",
    "    \"\"\"\n",
    "    cur, conn = create_database()\n",
    "    \n",
    "    drop_tables(cur, conn)\n",
    "    create_tables(cur, conn)\n",
    "\n",
    "    conn.close()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# DROP TABLES\n",
    "songplay_table_drop = \"DROP TABLE IF EXISTS songplays\"\n",
    "user_table_drop = \"DROP TABLE IF EXISTS users\"\n",
    "song_table_drop = \"DROP TABLE IF EXISTS songs\"\n",
    "artist_table_drop = \"DROP TABLE IF EXISTS artists\"\n",
    "time_table_drop = \"DROP TABLE IF EXISTS time\"\n",
    "\n",
    "\n",
    "# CREATE TABLES\n",
    "songplay_table_create = (\"\"\"CREATE TABLE songplays(\n",
    "songplay_id SERIAL,\n",
    "start_time TIMESTAMP REFERENCES time(start_time),\n",
    "user_id VARCHAR(50) REFERENCES users(user_id),\n",
    "level VARCHAR(50),\n",
    "song_id VARCHAR(100) REFERENCES songs(song_id),\n",
    "artist_id VARCHAR(100) REFERENCES artists(artist_id),\n",
    "session_id BIGINT,\n",
    "location VARCHAR(255),\n",
    "user_agent TEXT,\n",
    "PRIMARY KEY (songplay_id)) \"\"\")\n",
    "\n",
    "user_table_create = (\"\"\"CREATE TABLE users(\n",
    "user_id VARCHAR,\n",
    "firstName VARCHAR(255),\n",
    "lastName VARCHAR(255),\n",
    "gender VARCHAR(1),\n",
    "level VARCHAR(50),\n",
    "PRIMARY KEY (user_id)) \"\"\")\n",
    "\n",
    "song_table_create = (\"\"\"CREATE TABLE songs(\n",
    "song_id VARCHAR(100),\n",
    "title VARCHAR(255),\n",
    "artist_id VARCHAR(100),\n",
    "year INTEGER,\n",
    "duration DOUBLE PRECISION,\n",
    "PRIMARY KEY (song_id)) \"\"\")\n",
    "\n",
    "artist_table_create = (\"\"\"CREATE TABLE artists(\n",
    "artist_id VARCHAR(100),\n",
    "name VARCHAR(255),\n",
    "location VARCHAR(255),\n",
    "latitude DOUBLE PRECISION,\n",
    "longitude DOUBLE PRECISION,\n",
    "PRIMARY KEY (artist_id)) \"\"\")\n",
    "\n",
    "\n",
    "time_table_create = (\"\"\"CREATE TABLE time(\n",
    "start_time TIMESTAMP,\n",
    "hour INTEGER,\n",
    "day INTEGER,\n",
    "week INTEGER,\n",
    "month INTEGER,\n",
    "year INTEGER,\n",
    "weekday INTEGER,\n",
    "PRIMARY KEY (start_time)) \"\"\")\n",
    "\n",
    "# INSERT RECORDS\n",
    "\n",
    "songplay_table_insert = (\"\"\"INSERT INTO songplays (start_time, user_id, level, song_id, artist_id, session_id, location, user_agent) \n",
    " VALUES (%s, %s, %s, %s, %s, %s, %s, %s) \"\"\")\n",
    "\n",
    "user_table_insert = (\"\"\"INSERT INTO users (user_id, firstName, lastName, gender, level) VALUES (%s, %s, %s, %s, %s) \n",
    "ON CONFLICT (user_id) DO UPDATE SET firstName=users.firstName, lastName=users.lastName, gender=users.gender, level=users.level \"\"\")\n",
    "\n",
    "song_table_insert = (\"\"\"INSERT INTO songs (song_id, title, artist_id, year, duration) VALUES (%s, %s, %s, %s, %s)\n",
    "ON CONFLICT (song_id) DO UPDATE SET title=songs.title, artist_id=songs.artist_id,\n",
    "year=songs.year, duration=songs.duration \"\"\")\n",
    "\n",
    "artist_table_insert = (\"\"\"INSERT INTO artists (artist_id, name, location, latitude, longitude) VALUES (%s, %s, %s, %s, %s)\n",
    "ON CONFLICT (artist_id) DO UPDATE SET name=artists.name, location=artists.location, latitude=artists.latitude, \n",
    "longitude=artists.longitude \"\"\")\n",
    "\n",
    "time_table_insert = (\"\"\"INSERT INTO time (start_time, hour, day, week, month, year, weekday) VALUES (%s, %s, %s, %s, %s, %s, %s)\n",
    "ON CONFLICT (start_time) DO UPDATE SET hour=time.hour, day=time.day, week=time.week, month=time.month, \n",
    "year=time.year, weekday=time.weekday \"\"\")\n",
    "\n",
    "# FIND SONGS BY SONG ID AND ARTIST ID\n",
    "\n",
    "song_select_by_song_id_artist_id = (\"\"\"SELECT s.song_id, a.artist_id FROM songs s, artists a\n",
    "WHERE s.artist_id = a.artist_id  \n",
    "    AND s.title = %s\n",
    "    AND a.name = %s\n",
    "    AND s.duration = %s \"\"\")\n",
    "\n",
    "# FIND SONGS BY ID\n",
    "\n",
    "song_select = (\"\"\"SELECT COUNT(*) FROM songs s\n",
    "WHERE s.song_id = %s \"\"\")\n",
    "\n",
    "# FIND ARTISTS BY ID\n",
    "\n",
    "artist_select = (\"\"\"SELECT COUNT(*) FROM artists a\n",
    "WHERE a.artist_id = %s \"\"\")\n",
    "\n",
    "# FIND TIMES BY ID\n",
    "\n",
    "time_select = (\"\"\"SELECT COUNT(*) FROM time t\n",
    "WHERE t.start_time = %s \"\"\")\n",
    "\n",
    "# FIND USERS BY ID\n",
    "\n",
    "user_select = (\"\"\"SELECT COUNT(*) FROM users u\n",
    "WHERE u.user_id = %s \"\"\")\n",
    "\n",
    "\n",
    "# QUERY LISTS\n",
    "create_table_queries = [user_table_create, song_table_create, artist_table_create, time_table_create, songplay_table_create]\n",
    "drop_table_queries = [user_table_drop, song_table_drop, artist_table_drop, time_table_drop, songplay_table_drop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71 files found in data/song_data\n",
      "1/71 files processed.\n",
      "2/71 files processed.\n",
      "3/71 files processed.\n",
      "4/71 files processed.\n",
      "5/71 files processed.\n",
      "6/71 files processed.\n",
      "7/71 files processed.\n",
      "8/71 files processed.\n",
      "9/71 files processed.\n",
      "10/71 files processed.\n",
      "11/71 files processed.\n",
      "12/71 files processed.\n",
      "13/71 files processed.\n",
      "14/71 files processed.\n",
      "15/71 files processed.\n",
      "16/71 files processed.\n",
      "17/71 files processed.\n",
      "18/71 files processed.\n",
      "19/71 files processed.\n",
      "20/71 files processed.\n",
      "21/71 files processed.\n",
      "22/71 files processed.\n",
      "23/71 files processed.\n",
      "24/71 files processed.\n",
      "25/71 files processed.\n",
      "26/71 files processed.\n",
      "27/71 files processed.\n",
      "28/71 files processed.\n",
      "29/71 files processed.\n",
      "30/71 files processed.\n",
      "31/71 files processed.\n",
      "32/71 files processed.\n",
      "33/71 files processed.\n",
      "34/71 files processed.\n",
      "35/71 files processed.\n",
      "36/71 files processed.\n",
      "37/71 files processed.\n",
      "38/71 files processed.\n",
      "39/71 files processed.\n",
      "40/71 files processed.\n",
      "41/71 files processed.\n",
      "42/71 files processed.\n",
      "43/71 files processed.\n",
      "44/71 files processed.\n",
      "45/71 files processed.\n",
      "46/71 files processed.\n",
      "47/71 files processed.\n",
      "48/71 files processed.\n",
      "49/71 files processed.\n",
      "50/71 files processed.\n",
      "51/71 files processed.\n",
      "52/71 files processed.\n",
      "53/71 files processed.\n",
      "54/71 files processed.\n",
      "55/71 files processed.\n",
      "56/71 files processed.\n",
      "57/71 files processed.\n",
      "58/71 files processed.\n",
      "59/71 files processed.\n",
      "60/71 files processed.\n",
      "61/71 files processed.\n",
      "62/71 files processed.\n",
      "63/71 files processed.\n",
      "64/71 files processed.\n",
      "65/71 files processed.\n",
      "66/71 files processed.\n",
      "67/71 files processed.\n",
      "68/71 files processed.\n",
      "69/71 files processed.\n",
      "70/71 files processed.\n",
      "71/71 files processed.\n",
      "30 files found in data/log_data\n",
      "1/30 files processed.\n",
      "2/30 files processed.\n",
      "3/30 files processed.\n",
      "4/30 files processed.\n",
      "5/30 files processed.\n",
      "6/30 files processed.\n",
      "7/30 files processed.\n",
      "8/30 files processed.\n",
      "9/30 files processed.\n",
      "10/30 files processed.\n",
      "11/30 files processed.\n",
      "12/30 files processed.\n",
      "13/30 files processed.\n",
      "14/30 files processed.\n",
      "15/30 files processed.\n",
      "16/30 files processed.\n",
      "17/30 files processed.\n",
      "18/30 files processed.\n",
      "19/30 files processed.\n",
      "20/30 files processed.\n",
      "21/30 files processed.\n",
      "22/30 files processed.\n",
      "23/30 files processed.\n",
      "24/30 files processed.\n",
      "25/30 files processed.\n",
      "26/30 files processed.\n",
      "27/30 files processed.\n",
      "28/30 files processed.\n",
      "29/30 files processed.\n",
      "30/30 files processed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "from sql_queries import *\n",
    "\n",
    "\n",
    "def process_song_file(cur, filepath):\n",
    "    \n",
    "    # open song file\n",
    "    df = pd.read_json(filepath, typ='series')\n",
    "\n",
    "    # insert song record\n",
    "    song_data = df[['song_id','title','artist_id', 'year', 'duration']]\n",
    "  \n",
    "    # check for song_id duplicates\n",
    "    cur.execute(song_select, (song_data[['song_id']]))\n",
    "    results = cur.fetchone()\n",
    "    \n",
    "    if results[0] == 0:\n",
    "        cur.execute(song_table_insert, song_data)\n",
    "        \n",
    "    # insert artist record\n",
    "    artist_data = df[['artist_id','artist_name','artist_location', 'artist_latitude', 'artist_longitude']]\n",
    "    \n",
    "    # check for artist_id duplicates\n",
    "    cur.execute(artist_select, (artist_data[['artist_id']]))\n",
    "    results = cur.fetchone()\n",
    "   \n",
    "    if results[0] == 0:\n",
    "        cur.execute(artist_table_insert, artist_data)\n",
    "    \n",
    "        \n",
    "def process_log_file(cur, filepath):\n",
    "    # open log file\n",
    "    df = pd.read_json(filepath, lines=True)\n",
    "\n",
    "    # filter by NextSong action\n",
    "    df = df[df['page'] == 'NextSong']\n",
    "    # convert timestamp column to datetime\n",
    "    df['ts'] = pd.to_datetime(df['ts'], unit='ms')\n",
    "    \n",
    "    # insert time data records\n",
    "    time_data = [df['ts'], df['ts'].dt.hour, df['ts'].dt.day,\n",
    "                 df['ts'].dt.weekofyear, df['ts'].dt.month,\n",
    "                 df['ts'].dt.year,df['ts'].dt.weekday]\n",
    "    column_labels = ['ts', 'hour', 'day', 'week of year', 'month', 'year', 'weekday']\n",
    "    \n",
    "    assert isinstance(time_data, list), 'time_data should be a list'\n",
    "    assert isinstance(column_labels, list), 'column_labels should be a list'\n",
    "\n",
    "\n",
    "    dictionary = dict(zip(column_labels, time_data))\n",
    "    time_df = pd.DataFrame.from_dict(dictionary)\n",
    "    assert isinstance(time_df, pd.DataFrame), 'time_df should be a dataframe'\n",
    "    \n",
    "    \n",
    "    for i, row in time_df.iterrows():\n",
    "        # check for start_time duplicates\n",
    "        cur.execute(time_select, [row.ts])\n",
    "        results = cur.fetchone()\n",
    "        \n",
    "        if results[0] == 0: \n",
    "            cur.execute(time_table_insert, list(row))\n",
    "        \n",
    "\n",
    "    # load user table\n",
    "    user_df = df[['userId', 'firstName', 'lastName', 'gender', 'level']]\n",
    "    \n",
    "    # insert user records\n",
    "    for i, row in user_df.iterrows():\n",
    "        # check for user_id duplicates\n",
    "        cur.execute(user_select, (str(row.userId),))\n",
    "        results = cur.fetchone()\n",
    "        \n",
    "        if results[0] == 0:\n",
    "            cur.execute(user_table_insert, row)\n",
    "\n",
    "    # insert songplay records\n",
    "    for index, row in df.iterrows():\n",
    "        \n",
    "        # get song id and artist id from song and artist tables\n",
    "        cur.execute(song_select_by_song_id_artist_id, (row.song, row.artist, row.length))\n",
    "        results = cur.fetchone()\n",
    "        \n",
    "        if results:\n",
    "            songid, artistid = results\n",
    "        else:\n",
    "            songid, artistid = None, None\n",
    "\n",
    "        # insert songplay record\n",
    "        songplay_data = (row.ts, row.userId, row.level, songid, artistid, row.sessionId, row.location, row.userAgent)\n",
    "        cur.execute(songplay_table_insert, songplay_data)\n",
    "      \n",
    "    \n",
    "def process_data(cur, conn, filepath, func):\n",
    "    # get all files matching extension from directory\n",
    "    all_files = []\n",
    "    for root, dirs, files in os.walk(filepath):\n",
    "        files = glob.glob(os.path.join(root,'*.json'))\n",
    "        for f in files :\n",
    "            all_files.append(os.path.abspath(f))\n",
    "\n",
    "    # get total number of files found\n",
    "    num_files = len(all_files)\n",
    "    print('{} files found in {}'.format(num_files, filepath))\n",
    "\n",
    "    # iterate over files and process\n",
    "    for i, datafile in enumerate(all_files, 1):\n",
    "        func(cur, datafile)\n",
    "        conn.commit()\n",
    "        print('{}/{} files processed.'.format(i, num_files))\n",
    "\n",
    "        \n",
    "def main():\n",
    "    conn = psycopg2.connect(\"host=127.0.0.1 dbname=sparkifydb user=student password=student\")\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    process_data(cur, conn, filepath='data/song_data', func=process_song_file)\n",
    "    process_data(cur, conn, filepath='data/log_data', func=process_log_file)\n",
    " \n",
    "    cur.close()\n",
    "    conn.close()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
